\section{Machine Learning}

The importance of studying machine learning comes from the complexity of the
data-driven world in which we currently live. With the explosion of the
internet, the social networks and the spread of an ubiquitous model of
connectivity, more and more complex data need to be analyzed: from web traffic
statistics and electronic commerce data, to digital collections of images,
video, music, and of course text.

Our INCA group has made contributions in several machine learning sub-fields:
\begin{itemize}
\item \textbf{Ensemble Learning:} Multiple models, such as classifiers or regressors, are combined to solve a machine learning problem. In other words, ensembles combine a set of predictors to hopefully form a stronger hypothesis. Some research publications in this fields are \cite{NanculefVAM06}, \cite{ValleSAMF10}, \cite{FernandezVSA12} and \cite{NanculefVAM12}. Specifically for unbalanced data, we have proposed two ensemble techniques with asymmetric cost: \cite{NanculefVAM07} and \cite{OrmenoRVAA12}
\item \textbf{SVM and Kernel Methods:}
\item \textbf{Distributed Learning:}
When there are large data sources that are distributed geographically, it is
infeasible to centralize them in order to infer a model from them, due to the
transmission cost and memory restrictions. Another problem that is inherent to
Distributed Learning, arises from the different underlying laws of probability
that these data sources may have. Treating this data sources as if there came
from a single virtual table, could lead to generalization problems. To solve
this, we have proposed methods to build neighborhoods of similar data sources,
and then with ensemble methods build a general model that is able give better
results than other state of the art methods. We have mainly dealt with the
regression task \cite{Allende13}, \cite{Allende14}. 

\end{itemize}
